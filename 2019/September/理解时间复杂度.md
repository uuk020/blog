# 理解时间复杂度

一个程序的运行时间, 依赖于算法的好坏和问题的输入规模, 所谓输入规模是指输入量的多少
```c
int i = 1, sum = 0, n = 100;
for (; i <= n; i++) {
    sum = sum + i;
}
printf("%d", sum);
```

这个例子是算1到100总数和, 每行代码执行的时间都不一样, 我们只是粗略的估计. 每行代码运行时间为 time. 基于这个假设, 第1行执行代码则需要 time, 而2, 3行则需要 2n * time, 第5行执行1次, 所以这段代码总的执行时间就是 (2n  + 2) * time. 

```c
int sum = 0; n = 100;
sum = (1 + n) * n/2;
printf("%d", sum);
```

这段代码总的执行时间就是 3 * time

基于这个假设, 可以看出来**所有代码的执行时间 T(n) 与每行代码的执行次数成正比**  
总结为一个公式: **T(n) = O(f(n))**

T(n) 它表示代码执行的时间；n 表示数据规模的大小；f(n) 表示每行代码执行的次数总和。因为这是一个公式，所以用 f(n) 来表示. 公式中的O, 表示代码的执行时间 T(n) 与 f(n) 表达式成正比.

第一个例子用公式表示则是T(n) = O(2n + 2), 第二个例子同样也可以这样表示: T(n) = O(1). 这就是大 O 时间复杂度表示法. 大 O 时间实际上并不是具体代码执行时间, 而是表示**代码执行时间随着数据规模增长的变化趋势**, 所以, 也叫做渐进时间复杂度(时间复杂度)

**一般我们只关心循环执行次数最多的一段代码, 可以忽略公式中的加法常量, 与最高项相乘的常数, 系数和低项.** 也有推导公式
  1. 用常数1取代运行时间中的所有加法参数
  2. 在修改后的运行次数函数, 只保留最高阶项
  3. 如果最高阶项存在且不是1, 则去除与这个项相乘的常数

还是以前面两个例子来说明:
```c
int i = 1, sum = 0, n = 100;
for (; i <= n; i++) {
    sum = sum + i;
}
printf("%d", sum);
```
用公式表达的是T(n) = O(2n + 2) 根据推导公式1: T(n) = O(1n + 1); 推导公式2: 保留最高阶项则是T(n) = O(n). 这就是为什么第二例子的公式是O(1)的原因了.

常见的多项式时间复杂度
1. O(1)
```c
 int i = 8;
 int j = 6;
 int sum = i + j;
```
只要代码的执行时间不随着n的增大而增长, 这样代码时间复杂度都记作O(1). 只要没有循环,递归语句, 即使成千上万的代码, 其时间复杂度都是O(1).
2. O(n)
```c
int i = 1, sum = 0, n = 100;
for (; i <= n; i++) {
    sum = sum + i;
}
printf("%d", sum);
```
因为循环体须要执行n次, 所以时间复杂度为O(n)
3. O(logn)、O(nlogn)
```c
 int i = 1;
 while (i <= n)  {
   i = i * 2;
 }
```
从代码中可以看出，变量 i 的值从 1 开始取，每循环一次就乘以2. 当大于 n 时, 循环结束. 2<sup>x</sup> = log<sub>2</sub>n, 如果一段代码时间复杂度为O(logn), 循环执行n遍, 时间复杂度为 O(nlogn)

3. O(n²)、O(m * n)
```c
int i, j;
for (i = 0; i < n; i++) {
    for (j = 0; j < n; j++) {
        printf("%d", j);
    }
}
```
对于内层循环执行n遍, 其时间复杂度为O(n). 外层再循环执行n遍, 所以总时间复杂度为O(n²). 而O(m * n)则是把外层循环条件改成m.

常用的时间复杂度所耗费的时间从小到大依次:
O(1) < O(logn) < O(n) < O(nlogn) < O(n²) < O(n<sup>3</sup>) < O(2<sup>n</sup>) < O(n!) < O(n <sup>n</sup>)